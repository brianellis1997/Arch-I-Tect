# API Configuration
API_HOST=0.0.0.0
API_PORT=8000

# LLM Provider Configuration
# Options: ollama, openai, anthropic
LLM_PROVIDER=ollama

# Ollama Configuration (for local models)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llava

# OpenAI Configuration (if using GPT-4 Vision)
# Get your API key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your-openai-api-key-here
OPENAI_MODEL=gpt-4-vision-preview

# Anthropic Configuration (if using Claude 3)
# Get your API key from: https://console.anthropic.com/
ANTHROPIC_API_KEY=your-anthropic-api-key-here
ANTHROPIC_MODEL=claude-3-opus-20240229

# Application Settings
MAX_IMAGE_SIZE_MB=10
ALLOWED_IMAGE_TYPES=png,jpg,jpeg,webp

# Security Settings (optional)
# SECRET_KEY=your-secret-key-for-sessions
# ALLOWED_ORIGINS=http://localhost:5173,http://localhost:3000

# Logging Configuration
# LOG_LEVEL=INFO
# LOG_FILE=logs/arch-i-tect.log

# Rate Limiting (requests per minute)
# RATE_LIMIT_PER_MINUTE=10

# File Storage
# UPLOAD_DIR=uploads
# TEMP_DIR=temp

# Advanced Settings
# REQUEST_TIMEOUT_SECONDS=300
# MAX_WORKERS=4
# ENABLE_METRICS=false
# METRICS_PORT=9090